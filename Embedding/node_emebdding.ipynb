{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DomainNet source task embedding\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Source task data\n",
    "source_data = [\n",
    "    [\"convnext\", \"convnext_small\", 50223688, 83.616,8.68],\n",
    "    [\"convnext\", \"convnext_tiny\", 28589128, 82.52, 4.46],\n",
    "    [\"densenet\", \"densenet121\", 7978856, 74.434, 2.83],\n",
    "    [\"efficientnet\",\"efficientnet_b0\",5288548,77.692,0.39],\n",
    "    [\"efficientnet\",\"efficientnet_b3\",12233232,82.008,1.83],\n",
    "    [\"mobilenet\", \"mobilenet_v2\", 3504872, 72.154, 0.3],\n",
    "    [\"resnet\",\"resnet101\",68883240,78.468,11.4],\n",
    "    [\"resnet\", \"resnet50\", 25557032, 80.858, 4.09],\n",
    "    [\"resnet\", \"resnet18\", 11689512, 69.758, 1.81],\n",
    "    [\"resnet\", \"wide_resnet50_2\", 44549160, 81.886, 7.8]\n",
    "]\n",
    "\n",
    "# 对source task进行特征工程\n",
    "source_architecture_family = [row[0] for row in source_data]\n",
    "source_model_name = [row[1] for row in source_data]\n",
    "source_scalar_features = [[row[2], row[3], row[4]] for row in source_data]\n",
    "\n",
    "# One-hot编码\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "source_architecture_family_one_hot = enc.fit_transform(np.array(source_architecture_family).reshape(-1, 1)).toarray()\n",
    "source_model_name_one_hot = enc.fit_transform(np.array(source_model_name).reshape(-1, 1)).toarray()\n",
    "\n",
    "# 归一化scalar特征\n",
    "scaler = StandardScaler()\n",
    "source_scalar_features_normalized = scaler.fit_transform(source_scalar_features)\n",
    "\n",
    "source_embedding = np.concatenate((source_architecture_family_one_hot, source_model_name_one_hot, source_scalar_features_normalized), axis=1)\n",
    "np.save(\"DomainNet_source_embedding.npy\", source_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cm/shared/apps/anaconda3.10/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/cm/shared/apps/anaconda3.10/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/cm/shared/apps/anaconda3.10/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# 指定文件路径\n",
    "file_path = \"./target_embedding.xlsx\"\n",
    "\n",
    "# 读取 Excel 文件\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 初始化 OneHotEncoder 和 StandardScaler\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 选择需要进行 One-hot 编码的列和需要标准化的列\n",
    "datasets_name = enc.fit_transform(df[['dataset name']].values)\n",
    "domain_one_hot = enc.fit_transform(df[['domain']].values)\n",
    "categories_one_hot = enc.fit_transform(df[['categories']].values)\n",
    "\n",
    "# 选择需要进行标准化的列\n",
    "train_sample_size_normalized = scaler.fit_transform(df[['Train_Sample_Size']].values.reshape(-1, 1))\n",
    "num_pre_class_normalized = scaler.fit_transform(df[['num_pre_class']].values.reshape(-1, 1))\n",
    "\n",
    "# 合并处理后的数据\n",
    "processed_data = np.concatenate([datasets_name, domain_one_hot, num_pre_class_normalized, categories_one_hot, train_sample_size_normalized], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embedding = np.concatenate((processed_data, FM_embedding), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设 source_embedding 和 target_embedding 已经定义\n",
    "\n",
    "# 获取 source_embedding 和 target_embedding 的维度\n",
    "source_dim = s_embedding.shape[1]  # 13\n",
    "target_dim = target_embedding.shape[1]  # 33\n",
    "\n",
    "# 计算新的维度\n",
    "new_dim = source_dim + target_dim  # 46\n",
    "\n",
    "# 创建新的 embedding 数组，并用 0 填充\n",
    "new_source_embedding = np.zeros((s_embedding.shape[0], new_dim))\n",
    "new_target_embedding = np.zeros((target_embedding.shape[0], new_dim))\n",
    "\n",
    "# 将 source_embedding 的前 13 维复制到新的 embedding 数组中\n",
    "new_source_embedding[:, :source_dim] = s_embedding\n",
    "\n",
    "# 将 target_embedding 的后 33 维复制到新的 embedding 数组中\n",
    "new_target_embedding[:, source_dim:] = target_embedding\n",
    "\n",
    "# 保存新的 embedding 数组为 npy 文件\n",
    "np.save('DomainNet_new_source_embedding.npy', new_source_embedding)\n",
    "np.save('DomainNet_new_target_embedding.npy', new_target_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为 NumPy 文件\n",
    "np.save(\"target_domain_embedding.npy\", processed_data)\n",
    "\n",
    "# # 转换回 DataFrame 并保存为 Excel\n",
    "# processed_df = pd.DataFrame(processed_data)\n",
    "# processed_df.to_excel(\"processed_data.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 指定文件路径\n",
    "file_path = \"./target_embedding.xlsx\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DomainNet target task embedding\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Target task data\n",
    "target_data = [\n",
    "    [\"Domain Net_subset_1\", \"sketch\", 2, 121, 110,],\n",
    "    [\"Domain Net_subset_2\", \"sketch\", 4, 400, 349,],\n",
    "    [\"Domain Net_subset_3\", \"sketch\", 6, 600, 600,],\n",
    "]\n",
    "\n",
    "# 270, （10，30，50） ,（6个domain）,（任务1-任务15， label 2，2，2，4，4，4，8，8，8，16，16，16，32，32，32）\n",
    "\n",
    "target_dataset_name = [row[0] for row in target_data]\n",
    "target_domain_name = [row[1] for row in target_data]\n",
    "target_scalar_features = [[row[2], row[3], row[4]] for row in target_data]\n",
    "\n",
    "target_scalar_features_normalized = scaler.fit_transform(target_scalar_features)\n",
    "target_dataset_name_one_hot = enc.fit_transform(np.array(target_dataset_name).reshape(-1, 1)).toarray()\n",
    "target_domain_name_one_hot = enc.fit_transform(np.array(target_domain_name).reshape(-1, 1)).toarray()\n",
    "\n",
    "target_embedding = np.concatenate((target_dataset_name_one_hot, target_domain_name_one_hot, target_scalar_features_normalized), axis=1)\n",
    "\n",
    "np.save(\"target_embedding.npy\", target_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设 source_embedding 和 target_embedding 已经定义\n",
    "\n",
    "# 获取 source_embedding 和 target_embedding 的维度\n",
    "source_dim = s_embedding.shape[1]  # 13\n",
    "target_dim = target_embedding.shape[1]  # 33\n",
    "\n",
    "# 计算新的维度\n",
    "new_dim = source_dim + target_dim  # 46\n",
    "\n",
    "# 创建新的 embedding 数组，并用 0 填充\n",
    "new_source_embedding = np.zeros((s_embedding.shape[0], new_dim))\n",
    "new_target_embedding = np.zeros((target_embedding.shape[0], new_dim))\n",
    "\n",
    "# 将 source_embedding 的前 13 维复制到新的 embedding 数组中\n",
    "new_source_embedding[:, :source_dim] = s_embedding\n",
    "\n",
    "# 将 target_embedding 的后 33 维复制到新的 embedding 数组中\n",
    "new_target_embedding[:, source_dim:] = target_embedding\n",
    "\n",
    "# 保存新的 embedding 数组为 npy 文件\n",
    "np.save('DomainNet_new_source_embedding.npy', new_source_embedding)\n",
    "np.save('DomainNet_new_target_embedding.npy', new_target_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
